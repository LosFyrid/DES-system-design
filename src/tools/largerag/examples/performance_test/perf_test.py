"""
LargeRAG æ€§èƒ½æµ‹è¯•è„šæœ¬
====================================

æµ‹è¯•å†…å®¹ï¼š
1. å¯¹ rag_performance_test æ–‡ä»¶å¤¹ä¸­çš„10ç¯‡æ–‡çŒ®å»ºç«‹ç´¢å¼•
2. ä½¿ç”¨ question.txt ä¸­çš„10ä¸ªé—®é¢˜æµ‹è¯•RAGæ€§èƒ½
3. è®°å½•æ¯ä¸ªé—®é¢˜çš„ç­”æ¡ˆã€æ£€ç´¢æ€§èƒ½å’ŒLLMç”Ÿæˆè´¨é‡

è¿è¡Œæ–¹å¼ï¼š
    python examples/performance_test/perf_test.py              # æ­£å¸¸è¿è¡Œï¼ˆåŠ è½½å·²æœ‰ç´¢å¼•ï¼‰
    python examples/performance_test/perf_test.py --rebuild    # å¼ºåˆ¶é‡å»ºç´¢å¼•

æ•°æ®ç»“æ„ï¼š
    src/tools/largerag/data/rag_performance_test/
    â”œâ”€â”€ 1/ ... 10/  (10ç¯‡æ–‡çŒ®æ–‡ä»¶å¤¹)
    â””â”€â”€ question.txt (10ä¸ªæµ‹è¯•é—®é¢˜)
"""

import sys
import time
import json
import argparse
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°sys.path
# perf_test.py â†’ performance_test â†’ examples â†’ largerag â†’ tools â†’ src â†’ PROJECT_ROOT
project_root = Path(__file__).resolve().parents[5]  # å¾€ä¸Š5çº§
sys.path.insert(0, str(project_root))

from src.tools.largerag import LargeRAG
from src.tools.largerag.config.settings import SETTINGS


def print_section(title: str):
    """æ‰“å°åˆ†éš”çº¿"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80)


def print_subsection(title: str):
    """æ‰“å°å­æ ‡é¢˜"""
    print(f"\n--- {title} ---")


def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='LargeRAG æ€§èƒ½æµ‹è¯•')
    parser.add_argument('--rebuild', action='store_true',
                       help='å¼ºåˆ¶é‡å»ºç´¢å¼•ï¼ˆå³ä½¿å·²å­˜åœ¨ï¼‰')
    args = parser.parse_args()

    print_section("LargeRAG æ€§èƒ½æµ‹è¯• - 10ç¯‡æ–‡çŒ® + 10ä¸ªé—®é¢˜")

    # ============================================================
    # 1. è®¾ç½®æµ‹è¯•å‚æ•°
    # ============================================================
    print_section("æ­¥éª¤ 1: åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ")

    # æµ‹è¯•æ•°æ®è·¯å¾„
    test_data_dir = Path(__file__).parent.parent.parent / "data" / "rag_performance_test"
    question_file = test_data_dir / "question.txt"

    # è‡ªå®šä¹‰ collection åç§°ï¼ˆé¿å…ä¸å…¶ä»–ç´¢å¼•æ··æ·†ï¼‰
    collection_name = "rag_perf_test_10papers"

    print(f"\næµ‹è¯•æ•°æ®ç›®å½•: {test_data_dir}")
    print(f"é—®é¢˜æ–‡ä»¶: {question_file}")
    print(f"Collection åç§°: {collection_name}")

    # æ£€æŸ¥æµ‹è¯•æ•°æ®æ˜¯å¦å­˜åœ¨
    if not test_data_dir.exists():
        print(f"\nâœ— é”™è¯¯: æµ‹è¯•æ•°æ®ç›®å½•ä¸å­˜åœ¨: {test_data_dir}")
        return False

    if not question_file.exists():
        print(f"\nâœ— é”™è¯¯: é—®é¢˜æ–‡ä»¶ä¸å­˜åœ¨: {question_file}")
        return False

    # ç»Ÿè®¡æ–‡çŒ®æ•°é‡
    literature_folders = [d for d in test_data_dir.iterdir() if d.is_dir()]
    print(f"\nâœ“ æ£€æµ‹åˆ° {len(literature_folders)} ä¸ªæ–‡çŒ®æ–‡ä»¶å¤¹")

    # ============================================================
    # 2. åˆå§‹åŒ– LargeRAGï¼ˆä½¿ç”¨è‡ªå®šä¹‰ collectionï¼‰
    # ============================================================
    print_section("æ­¥éª¤ 2: åˆå§‹åŒ– LargeRAG")

    print(f"\nä½¿ç”¨è‡ªå®šä¹‰ collection: {collection_name}")
    print("(è¿™æ ·ä¸ä¼šå½±å“å…¶ä»–å·²æœ‰çš„ç´¢å¼•)")

    start_time = time.time()
    rag = LargeRAG(collection_name=collection_name)
    init_time = time.time() - start_time

    print(f"\nâœ“ LargeRAG åˆå§‹åŒ–å®Œæˆ (è€—æ—¶: {init_time:.2f}ç§’)")

    # è·å–å½“å‰é…ç½®å‚æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    retrieval_top_k = SETTINGS.retrieval.rerank_top_n  # æœ€ç»ˆè¿”å›ç»™ç”¨æˆ·çš„æ–‡æ¡£æ•°
    print(f"\nå½“å‰é…ç½®å‚æ•°:")
    print(f"  - å‘é‡æ£€ç´¢å¬å›æ•°: {SETTINGS.retrieval.similarity_top_k}")
    print(f"  - Rerankerè¿”å›æ•°: {SETTINGS.retrieval.rerank_top_n}")
    print(f"  - Rerankerå¯ç”¨:   {SETTINGS.reranker.enabled}")
    print(f"  - LLMæ¨¡å‹:        {SETTINGS.llm.model}")
    print(f"  - æ¸©åº¦:           {SETTINGS.llm.temperature}")
    print(f"  - æœ€å¤§tokens:     {SETTINGS.llm.max_tokens}")

    # ============================================================
    # 3. æ„å»ºç´¢å¼•ï¼ˆæˆ–åŠ è½½å·²æœ‰ç´¢å¼•ï¼‰
    # ============================================================
    print_section("æ­¥éª¤ 3: æ„å»º/åŠ è½½ç´¢å¼•")

    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å»ºç´¢å¼•
    need_rebuild = args.rebuild  # ç”¨æˆ·æ˜ç¡®è¦æ±‚é‡å»º

    if not need_rebuild and rag.query_engine is not None:
        # æœ‰ç´¢å¼•ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºç©º
        stats_temp = rag.get_stats()
        index_count = stats_temp['index_stats'].get('document_count', 0)
        if index_count == 0:
            print("\nâš ï¸  æ£€æµ‹åˆ°ç´¢å¼•ä¸ºç©ºï¼ˆå¯èƒ½ä¹‹å‰æ„å»ºå¤±è´¥ï¼‰ï¼Œå°†å¼ºåˆ¶é‡å»º...")
            need_rebuild = True
        else:
            print(f"\nâœ“ æ£€æµ‹åˆ°å·²æœ‰ç´¢å¼•ï¼ˆ{index_count} ä¸ªèŠ‚ç‚¹ï¼‰ï¼Œè·³è¿‡æ„å»ºæ­¥éª¤")
            print("  æç¤º: ä½¿ç”¨ --rebuild å‚æ•°å¯å¼ºåˆ¶é‡å»ºç´¢å¼•")

    if need_rebuild or rag.query_engine is None:
        if need_rebuild:
            print("\nğŸ”„ å¼ºåˆ¶é‡å»ºç´¢å¼•...")
        else:
            print("\næœªæ£€æµ‹åˆ°å·²æœ‰ç´¢å¼•ï¼Œå¼€å§‹æ„å»º...")

        print(f"æ–‡çŒ®æ•°é‡: {len(literature_folders)}")

        start_time = time.time()
        success = rag.index_from_folders(str(test_data_dir))
        index_time = time.time() - start_time

        if not success:
            print("\nâœ— ç´¢å¼•æ„å»ºå¤±è´¥")
            return False

        print(f"\nâœ“ ç´¢å¼•æ„å»ºæˆåŠŸ (è€—æ—¶: {index_time:.2f}ç§’ / {index_time/60:.2f}åˆ†é’Ÿ)")

    # æ˜¾ç¤ºç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
    stats = rag.get_stats()
    index_stats = stats['index_stats']
    doc_stats = stats['doc_processing_stats']

    print_subsection("ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯")
    print(f"  Collection: {index_stats.get('collection_name', 'N/A')}")
    print(f"  ç´¢å¼•èŠ‚ç‚¹æ•°: {index_stats.get('document_count', 0)}")
    print(f"  å¤„ç†æ–‡æ¡£æ•°: {doc_stats.get('processed', 0)}")

    # ============================================================
    # 4. è¯»å–æµ‹è¯•é—®é¢˜
    # ============================================================
    print_section("æ­¥éª¤ 4: è¯»å–æµ‹è¯•é—®é¢˜")

    with open(question_file, 'r', encoding='utf-8') as f:
        questions = [line.strip() for line in f.readlines() if line.strip()]

    print(f"\nâœ“ è¯»å–åˆ° {len(questions)} ä¸ªé—®é¢˜\n")

    for i, q in enumerate(questions, 1):
        print(f"  Q{i}: {q}")

    # ============================================================
    # 5. æ‰§è¡Œæµ‹è¯• - å¯¹æ¯ä¸ªé—®é¢˜è¿›è¡ŒæŸ¥è¯¢
    # ============================================================
    print_section("æ­¥éª¤ 5: æ‰§è¡Œæ€§èƒ½æµ‹è¯•")

    results = []
    total_query_time = 0
    total_retrieval_time = 0

    print("\nå¼€å§‹æµ‹è¯•...\n")

    for i, question in enumerate(questions, 1):
        print_subsection(f"é—®é¢˜ {i}/{len(questions)}")
        print(f"é—®é¢˜: {question}\n")

        # 5.1 æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£ï¼ˆä¸ä½¿ç”¨LLMï¼‰
        print("  [1/2] æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£...")
        start_time = time.time()
        similar_docs = rag.get_similar_docs(question, top_k=retrieval_top_k)
        retrieval_time = time.time() - start_time
        total_retrieval_time += retrieval_time

        print(f"  âœ“ æ£€ç´¢å®Œæˆ (è€—æ—¶: {retrieval_time:.2f}ç§’)")
        print(f"  æ£€ç´¢åˆ° {len(similar_docs)} ä¸ªç›¸å…³æ–‡æ¡£")

        # æ˜¾ç¤ºæ£€ç´¢çš„æ–‡æ¡£åˆ†æ•°
        if similar_docs:
            print(f"  ç›¸ä¼¼åº¦åˆ†æ•°èŒƒå›´: {similar_docs[0]['score']:.4f} ~ {similar_docs[-1]['score']:.4f}")

        # 5.2 ç”Ÿæˆå›ç­”ï¼ˆä½¿ç”¨LLMï¼‰
        print("\n  [2/2] ç”Ÿæˆå›ç­”...")
        start_time = time.time()
        answer = rag.query(question)
        query_time = time.time() - start_time
        total_query_time += query_time

        print(f"  âœ“ å›ç­”ç”Ÿæˆå®Œæˆ (è€—æ—¶: {query_time:.2f}ç§’)")

        # æ˜¾ç¤ºå›ç­”ï¼ˆå‰200å­—ç¬¦ï¼‰
        answer_preview = answer[:200] + "..." if len(answer) > 200 else answer
        print(f"\n  å›ç­”:\n  {answer_preview}\n")

        # è®°å½•ç»“æœ
        result = {
            "question_id": i,
            "question": question,
            "answer": answer,
            "retrieval_time_sec": round(retrieval_time, 2),
            "query_time_sec": round(query_time, 2),
            "num_retrieved_docs": len(similar_docs),
            "similarity_scores": [round(doc['score'], 4) for doc in similar_docs],
            "top_doc_sources": [
                {
                    "doc_hash": doc['metadata'].get('doc_hash', 'N/A')[:16],
                    "page_idx": doc['metadata'].get('page_idx', 'N/A'),
                    "score": round(doc['score'], 4)
                }
                for doc in similar_docs[:3]  # åªè®°å½•å‰3ä¸ªæ–‡æ¡£æ¥æº
            ]
        }
        results.append(result)

    # ============================================================
    # 6. ç»Ÿè®¡æµ‹è¯•ç»“æœ
    # ============================================================
    print_section("æ­¥éª¤ 6: æµ‹è¯•ç»“æœç»Ÿè®¡")

    avg_retrieval_time = total_retrieval_time / len(questions)
    avg_query_time = total_query_time / len(questions)

    print("\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
    print(f"  æ€»é—®é¢˜æ•°:           {len(questions)}")
    print(f"  å¹³å‡æ£€ç´¢æ—¶é—´:       {avg_retrieval_time:.2f}ç§’")
    print(f"  å¹³å‡æŸ¥è¯¢æ—¶é—´:       {avg_query_time:.2f}ç§’")
    print(f"  æ€»æ£€ç´¢æ—¶é—´:         {total_retrieval_time:.2f}ç§’")
    print(f"  æ€»æŸ¥è¯¢æ—¶é—´:         {total_query_time:.2f}ç§’")

    print("\nğŸ“Š ç´¢å¼•ç»Ÿè®¡:")
    print(f"  æ–‡çŒ®æ•°é‡:           {len(literature_folders)}")
    print(f"  ç´¢å¼•èŠ‚ç‚¹æ•°:         {index_stats.get('document_count', 0)}")
    print(f"  Collection:         {collection_name}")

    # ============================================================
    # 7. ä¿å­˜æµ‹è¯•ç»“æœåˆ° JSON
    # ============================================================
    print_section("æ­¥éª¤ 7: ä¿å­˜æµ‹è¯•ç»“æœ")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(__file__).parent / "test_results"
    output_dir.mkdir(exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"perf_test_{timestamp}.json"

    # æ•´åˆæ‰€æœ‰ç»“æœ
    full_results = {
        "test_info": {
            "timestamp": timestamp,
            "test_data_dir": str(test_data_dir),
            "collection_name": collection_name,
            "num_literature": len(literature_folders),
            "num_questions": len(questions),
        },
        "config_parameters": {
            "similarity_top_k": SETTINGS.retrieval.similarity_top_k,
            "rerank_top_n": SETTINGS.retrieval.rerank_top_n,
            "similarity_threshold": SETTINGS.retrieval.similarity_threshold,
            "reranker_enabled": SETTINGS.reranker.enabled,
            "reranker_model": SETTINGS.reranker.model,
            "llm_model": SETTINGS.llm.model,
            "llm_temperature": SETTINGS.llm.temperature,
            "llm_max_tokens": SETTINGS.llm.max_tokens,
            "chunk_size": SETTINGS.document_processing.chunk_size,
            "chunk_overlap": SETTINGS.document_processing.chunk_overlap,
        },
        "performance_summary": {
            "avg_retrieval_time_sec": round(avg_retrieval_time, 2),
            "avg_query_time_sec": round(avg_query_time, 2),
            "total_retrieval_time_sec": round(total_retrieval_time, 2),
            "total_query_time_sec": round(total_query_time, 2),
        },
        "index_stats": index_stats,
        "questions_and_answers": results,
    }

    # ä¿å­˜åˆ° JSON
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(full_results, f, ensure_ascii=False, indent=2)

    print(f"\nâœ“ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    # ============================================================
    # 8. å®Œæˆ
    # ============================================================
    print_section("æµ‹è¯•å®Œæˆï¼")

    print("\nâœ… æ‰€æœ‰æµ‹è¯•å·²å®Œæˆ")
    print(f"\næµ‹è¯•ç»“æœæ–‡ä»¶: {output_file}")
    print("\nå¯ä»¥æŸ¥çœ‹ JSON æ–‡ä»¶è·å–è¯¦ç»†ç»“æœï¼ŒåŒ…æ‹¬:")
    print("  - æ¯ä¸ªé—®é¢˜çš„å®Œæ•´å›ç­”")
    print("  - æ£€ç´¢æ€§èƒ½æŒ‡æ ‡ï¼ˆæ—¶é—´ã€ç›¸ä¼¼åº¦åˆ†æ•°ï¼‰")
    print("  - æ–‡æ¡£æ¥æºä¿¡æ¯ï¼ˆdoc_hash, page_idxï¼‰")

    print("\n" + "=" * 80 + "\n")

    return True


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
